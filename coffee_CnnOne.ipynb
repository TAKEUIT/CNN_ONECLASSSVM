{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time, os, copy, argparse\n",
    "import multiprocessing\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e15621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'three_data/train'\n",
    "val_dir = 'three_data/val'\n",
    "test_dir = 'three_data/test'\n",
    "one_test_dir = 'three_data/one_test'\n",
    "one_val_dir = 'three_data/one_val'\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "num_classes = 4\n",
    "\n",
    "num_cpu = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_base = 'three_data/train'\n",
    "img_path = path_base + '/peaberry/1001.jpg'\n",
    "img = Image.open(img_path)\n",
    "img\n",
    "\n",
    "img_np = np.array(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor() \n",
    "])\n",
    "img_tr = transform(img)\n",
    "\n",
    "img_np = np.array(img_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27265751",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n",
    "print(\"正規化前の平均値（mean）と標準偏差（std）:\")\n",
    "print(\"画像の平均値（mean）      :\", mean)\n",
    "print(\"画像の標準偏差（std）:\", std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_norm = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean, std)  \n",
    "])\n",
    "img_normalized = transform_norm(img)\n",
    "img_np = np.array(img_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_normalized = transform_norm(img)\n",
    "img_normalized = np.array(img_normalized)\n",
    "img_normalized = img_normalized.transpose(1, 2, 0)\n",
    "\n",
    "plt.imshow(img_normalized)\n",
    "plt.xticks([]) \n",
    "plt.yticks([]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_nor = transform_norm(img)\n",
    "mean, std = img_nor.mean([1,2]), img_nor.std([1,2])\n",
    "print(\"正規化された画像の平均値と標準偏差:\")\n",
    "print(\"画像の平均値        :\", mean)\n",
    "print(\"画像の標準偏差      :\", std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079dc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の正規化に使用する平均値（mean）と標準偏差（std）の変数を作成する\n",
    "mean = [0.8609, 0.8271, 0.7862]\n",
    "std = [0.1960, 0.2179, 0.2592]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size=(256, 256)), \n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean, std) \n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(size=(256, 256)),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean, std)  \n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=(256, 256)),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean, std)  \n",
    "    ]),\n",
    "    'one_test': transforms.Compose([\n",
    "        transforms.Resize(size=(256, 256)),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean, std)  \n",
    "    ]),\n",
    "    'one_val': transforms.Compose([\n",
    "        transforms.Resize(size=(256, 256)),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean, std)  \n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "for directory in [train_dir, val_dir, test_dir]:\n",
    "    checkpoints_path = os.path.join(directory, '.ipynb_checkpoints')\n",
    "    if os.path.exists(checkpoints_path):\n",
    "        shutil.rmtree(checkpoints_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bee062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train': datasets.ImageFolder(root=train_dir, transform=image_transforms['train']),\n",
    "    'val': datasets.ImageFolder(root=val_dir, transform=image_transforms['val']),\n",
    "    'test': datasets.ImageFolder(root=test_dir, transform=image_transforms['test']),\n",
    "    'one_test': datasets.ImageFolder(root=one_test_dir, transform=image_transforms['one_test']),\n",
    "    'one_val': datasets.ImageFolder(root=one_val_dir, transform=image_transforms['one_val']),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62881799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef5dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = dataset['train'].classes\n",
    "print('このデータセットには', len(classes), '個のクラスがあり、クラスは次の通りです:', classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f56975",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    'train': len(dataset['train']),\n",
    "    'val': len(dataset['val']),\n",
    "    'test': len(dataset['test']),\n",
    "    'one_val': len(dataset['one_val']),\n",
    "    'one_test': len(dataset['one_test']),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e32925",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"トレーニングデータの画像数   :\", dataset_sizes['train'])\n",
    "print(\"検証データの画像数           :\", dataset_sizes['val'])\n",
    "print(\"テストデータの画像数         :\", dataset_sizes['test'])\n",
    "print(\"テストデータの画像数         :\", dataset_sizes['one_test'])\n",
    "print(\"テストデータの画像数         :\", dataset_sizes['one_val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3524c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': data.DataLoader(dataset['train'], batch_size=batch_size, shuffle=True, num_workers=num_cpu, pin_memory=True, drop_last=True),\n",
    "    'val'  : data.DataLoader(dataset['val'], batch_size=batch_size, shuffle=True, num_workers=num_cpu, pin_memory=True, drop_last=True),\n",
    "    'test' : data.DataLoader(dataset['test'], batch_size=batch_size, shuffle=True, num_workers=num_cpu, pin_memory=True, drop_last=True),\n",
    "    'one_test' : data.DataLoader(dataset['one_test'], batch_size=batch_size, shuffle=True, num_workers=num_cpu, pin_memory=True, drop_last=True),\n",
    "    'one_val' : data.DataLoader(dataset['one_val'], batch_size=batch_size, shuffle=True, num_workers=num_cpu, pin_memory=True, drop_last=True)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88393f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, mean=[0.8782, 0.8429, 0.8053], std=[0.1224, 0.1398, 0.1678]):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean \n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "class_names = ['defect', 'longberry', 'peaberry', 'premium']\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out, title=[class_names[x] for x in classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c930a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['train'].class_to_idx)\n",
    "print(dataset['val'].class_to_idx)\n",
    "print(dataset['test'].class_to_idx)\n",
    "print(dataset['one_test'].class_to_idx)\n",
    "print(dataset['one_val'].class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = images.to(device), labels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b20f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nEfficientNetV2を読み込んでいます \\n\")\n",
    "model_ft = models.efficientnet_v2_s(pretrained=True)\n",
    "num_ftrs = model_ft.classifier[1].in_features\n",
    "model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "model_ft = model_ft.to(device)\n",
    "for num, (name, param) in enumerate(model_ft.named_parameters()):\n",
    "    print(num, name, param.requires_grad)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb47d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('モデルの概要:\\n')\n",
    "summary(model_ft, input_size=(3, 256, 256))\n",
    "print(model_ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=SummaryWriter('/content/content/runs/summary_1')\n",
    "writer.add_graph(model_ft, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c33e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = torch.unique(labels)\n",
    "print(f\"Unique labels: {unique_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8deda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=30):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    writer = SummaryWriter(\"content/runs/model_percobaan_1\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device, non_blocking=False)\n",
    "                labels = labels.to(device, non_blocking=False)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n",
    "            else:\n",
    "                writer.add_scalar('Valid/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Valid/Accuracy', epoch_acc, epoch)\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    writer.close()\n",
    "    return model\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 5593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir content/runs\n",
    "%reload_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bccdd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model_percobaan_1.pth'\n",
    "print(\"\\nモデルを保存しています...\")\n",
    "torch.save(model_ft, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d02ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "PATH = 'model_percobaan_1.pth'\n",
    "print(\"\\nモデルを復元しています...\")\n",
    "model_ft = torch.load(PATH)\n",
    "\n",
    "model_ft.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "\n",
    "                if preds[j] < len(class_names):\n",
    "                    ax.set_title(f'yosoku: {class_names[preds[j]]}')\n",
    "                else:\n",
    "                    ax.set_title('yosoku: humei')\n",
    "\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "import torch\n",
    "\n",
    "def computeTestSetAccuracy(model, criterion):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for j, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if labels.ndim > 1: \n",
    "                labels = labels.argmax(dim=1)\n",
    "\n",
    "            outputs = model_ft(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            correct_counts = predictions.eq(labels)\n",
    "            acc = correct_counts.sum().float() / labels.size(0)\n",
    "\n",
    "            test_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "            print(\"テストバッチ番号: {:03d}, テスト損失: {:.4f}, 精度: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "\n",
    "    avg_test_loss = test_loss / dataset_sizes['test']\n",
    "    avg_test_acc = test_acc / dataset_sizes['test']\n",
    "\n",
    "    print(\"\\nテストセット: 平均損失: {:.4f}, 平均精度: {:.4f}\".format(avg_test_loss, avg_test_acc))\n",
    "    return avg_test_loss, avg_test_acc\n",
    "\n",
    "def plot_outputs_without_reduction_and_save_csv(model, dataloader, csv_filename=\"outputs_with_labels.csv\"):\n",
    "    model.eval()\n",
    "    outputs_list = []\n",
    "    true_labels_list = []\n",
    "    predicted_labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, true_labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            true_labels = true_labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            outputs_list.append(outputs.cpu().numpy())\n",
    "            true_labels_list.append(true_labels.cpu().numpy())\n",
    "\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            predicted_labels_list.append(predicted_labels.cpu().numpy())\n",
    "\n",
    "    outputs_all = np.concatenate(outputs_list, axis=0)\n",
    "    true_labels_all = np.concatenate(true_labels_list, axis=0)\n",
    "\n",
    "    if outputs_all.shape[1] >= 3:\n",
    "        outputs_3d = outputs_all[:, :3]\n",
    "    else:\n",
    "        raise ValueError(\"モデル出力の次元が3未満です。3次元以上の出力が必要です。\")\n",
    "\n",
    "    data_to_save = np.column_stack((outputs_3d, true_labels_all, predicted_labels_all))\n",
    "    df = pd.DataFrame(data_to_save, columns=[\"Output1\", \"Output2\", \"Output3\", \"True Label\", \"Predicted Label\"])\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"データが{csv_filename}に保存されました。\")\n",
    "\n",
    "    centers = {}\n",
    "    for label in np.unique(true_labels_all):\n",
    "        centers[label] = outputs_3d[true_labels_all == label].mean(axis=0)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(len(np.unique(true_labels_all))):\n",
    "        idx = true_labels_all == i\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=outputs_3d[idx, 0],\n",
    "            y=outputs_3d[idx, 1],\n",
    "            z=outputs_3d[idx, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=2),  \n",
    "            name=f'Class {i}'\n",
    "        ))\n",
    "\n",
    "    for label, center in centers.items():\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[0, center[0]],\n",
    "            y=[0, center[1]],\n",
    "            z=[0, center[2]],\n",
    "            mode='lines',\n",
    "            line=dict(width=4),\n",
    "            name=f'Class {label} Center Line'\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title=\"Output Dimension 1\",\n",
    "        yaxis_title=\"Output Dimension 2\",\n",
    "        zaxis_title=\"Output Dimension 3\"\n",
    "    ), title=\"3D Output Space with Center Lines to Origin\")\n",
    "\n",
    "    fig.show()\n",
    "    fig.write_html(\"3D_plot_without_reduction.html\")\n",
    "\n",
    "plot_outputs_without_reduction_and_save_csv(model_ft, dataloaders['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeba0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['one_val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "\n",
    "                if preds[j] < len(class_names):\n",
    "                    ax.set_title(f'yosoku: {class_names[preds[j]]}')\n",
    "                else:\n",
    "                    ax.set_title('yosoku: humei')  \n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "        \n",
    "\n",
    "import torch\n",
    "\n",
    "def computeTestSetAccuracy(model, criterion):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for j, (inputs, labels) in enumerate(dataloaders['one_test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if labels.ndim > 1: \n",
    "                labels = labels.argmax(dim=1)\n",
    "\n",
    "            outputs = model_ft(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            correct_counts = predictions.eq(labels)\n",
    "            acc = correct_counts.sum().float() / labels.size(0)\n",
    "\n",
    "            test_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "            print(\"テストバッチ番号: {:03d}, テスト損失: {:.4f}, 精度: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "\n",
    "    avg_test_loss = test_loss / dataset_sizes['one_test']\n",
    "    avg_test_acc = test_acc / dataset_sizes['one_test']\n",
    "\n",
    "    print(\"\\nテストセット: 平均損失: {:.4f}, 平均精度: {:.4f}\".format(avg_test_loss, avg_test_acc))\n",
    "    return avg_test_loss, avg_test_acc\n",
    "\n",
    "idx_to_class = {v: k for k, v in dataset['one_test'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_outputs_without_reduction_and_save_csv(model, dataloader, csv_filename=\"soutputs_with_labels.csv\"):\n",
    "    model.eval()\n",
    "    outputs_list = []\n",
    "    true_labels_list = []\n",
    "    predicted_labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, true_labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            true_labels = true_labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            outputs_list.append(outputs.cpu().numpy())\n",
    "            true_labels_list.append(true_labels.cpu().numpy())\n",
    "\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            predicted_labels_list.append(predicted_labels.cpu().numpy())\n",
    "\n",
    "    outputs_all = np.concatenate(outputs_list, axis=0)\n",
    "    true_labels_all = np.concatenate(true_labels_list, axis=0)\n",
    "    predicted_labels_all = np.concatenate(predicted_labels_list, axis=0)\n",
    "\n",
    "    if outputs_all.shape[1] >= 3:\n",
    "        outputs_3d = outputs_all[:, :3]\n",
    "    else:\n",
    "        raise ValueError(\"モデル出力の次元が3未満です。3次元以上の出力が必要です。\")\n",
    "\n",
    "    data_to_save = np.column_stack((outputs_3d, true_labels_all, predicted_labels_all))\n",
    "    df = pd.DataFrame(data_to_save, columns=[\"Output1\", \"Output2\", \"Output3\", \"True Label\", \"Predicted Label\"])\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"データが{csv_filename}に保存されました。\")\n",
    "\n",
    "    centers = {}\n",
    "    for label in np.unique(true_labels_all):\n",
    "        centers[label] = outputs_3d[true_labels_all == label].mean(axis=0)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(len(np.unique(true_labels_all))):\n",
    "        idx = true_labels_all == i\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=outputs_3d[idx, 0],\n",
    "            y=outputs_3d[idx, 1],\n",
    "            z=outputs_3d[idx, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=2),\n",
    "            name=f'Class {i}'\n",
    "        ))\n",
    "\n",
    "    for label, center in centers.items():\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[0, center[0]],\n",
    "            y=[0, center[1]],\n",
    "            z=[0, center[2]],\n",
    "            mode='lines',\n",
    "            line=dict(width=4),\n",
    "            name=f'Class {label} Center Line'\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title=\"Output Dimension 1\",\n",
    "        yaxis_title=\"Output Dimension 2\",\n",
    "        zaxis_title=\"Output Dimension 3\"\n",
    "    ), title=\"3D Output Space with Center Lines to Origin\")\n",
    "\n",
    "    fig.show()\n",
    "    fig.write_html(\"3D_plot_without_reduction.html\")\n",
    "\n",
    "plot_outputs_without_reduction_and_save_csv(model_ft, dataloaders['one_test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "num_classes = 4  \n",
    "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "model = model_ft\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, classes in dataloaders['test']:\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "            if t < num_classes and p < num_classes:\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85785157",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh -L localhost:8989:192.168.11.10:8989 ratchet_VPNdef plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "  \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e88986",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm           = np.array([[1.2000e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
    "        [0.0000e+00, 1.1990e+03, 1.0000e+00, 0.0000e+00],\n",
    "        [0.0000e+00, 1.0000e+00, 1.1990e+03, 0.0000e+00],\n",
    "        [1.9100e+02, 2.3500e+02, 7.6700e+02, 7.0000e+00]]),\n",
    "                      normalize    = True,\n",
    "                      target_names = [ 'longberry', 'peaberry', 'premium','deffect'],\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369647fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "data = pd.read_csv('soutputs_with_labels.csv')\n",
    "\n",
    "X = data[['Output1', 'Output2', 'Output3']].values\n",
    "true_labels = data['True Label'].values  # 真のラベル\n",
    "\n",
    "good_data = data[data['True Label'].isin([0, 1, 2])]\n",
    "X_good = good_data[['Output1', 'Output2', 'Output3']].values\n",
    "\n",
    "bad_data = data[data['True Label'] == 3]\n",
    "X_bad = bad_data[['Output1', 'Output2', 'Output3']].values\n",
    "\n",
    "oc_svm = OneClassSVM(kernel='rbf', gamma=1, nu=0.02)\n",
    "oc_svm.fit(X_bad)\n",
    "oc_svm.fit(X_good)\n",
    "\n",
    "y_pred = oc_svm.predict(X) \n",
    "\n",
    "good_points = X[y_pred == 1]\n",
    "defective_points = X[y_pred == -1]\n",
    "\n",
    "x = np.linspace(X[:, 0].min(), X[:, 0].max(), 30)\n",
    "y = np.linspace(X[:, 1].min(), X[:, 1].max(), 30)\n",
    "z = np.linspace(X[:, 2].min(), X[:, 2].max(), 30)\n",
    "xx, yy, zz = np.meshgrid(x, y, z)\n",
    "grid = np.c_[xx.ravel(), yy.ravel(), zz.ravel()]\n",
    "decision_scores = oc_svm.decision_function(grid)\n",
    "decision_scores = decision_scores.reshape(xx.shape)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=good_points[:, 0],\n",
    "    y=good_points[:, 1],\n",
    "    z=good_points[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color='blue', opacity=0.8),\n",
    "    name='Good (Predicted)'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=defective_points[:, 0],\n",
    "    y=defective_points[:, 1],\n",
    "    z=defective_points[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color='red', opacity=0.8),\n",
    "    name='Defective (Predicted)'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Isosurface(\n",
    "    x=grid[:, 0],\n",
    "    y=grid[:, 1],\n",
    "    z=grid[:, 2],\n",
    "    value=decision_scores.ravel(),\n",
    "    isomin=-0.01, \n",
    "    isomax=0.01,\n",
    "    opacity=0.3,\n",
    "    surface_count=1, \n",
    "    colorscale='Viridis',\n",
    "    name='Decision Boundary'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='One-Class SVM: 3D Decision Boundary with Data Points',\n",
    "    scene=dict(\n",
    "        xaxis_title='Output1',\n",
    "        yaxis_title='Output2',\n",
    "        zaxis_title='Output3',\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0.1, y=0.9, bgcolor='rgba(255,255,255,0.5)'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d762ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "data = pd.read_csv('outputs_with_labels.csv')\n",
    "\n",
    "X = data[['Output1', 'Output2', 'Output3']].values\n",
    "true_labels = data['True Label'].values \n",
    "\n",
    "good_data = data[data['True Label'].isin([0, 1, 2])]\n",
    "X_good = good_data[['Output1', 'Output2', 'Output3']].values\n",
    "\n",
    "bad_data = data[data['True Label'] == 3]\n",
    "X_bad = bad_data[['Output1', 'Output2', 'Output3']].values\n",
    "\n",
    "oc_svm = OneClassSVM(kernel='rbf', gamma=1, nu=0.02)\n",
    "oc_svm.fit(X_good)\n",
    "\n",
    "y_pred = oc_svm.predict(X) \n",
    "\n",
    "good_points = X[y_pred == 1]\n",
    "defective_points = X[y_pred == -1]\n",
    "\n",
    "x = np.linspace(X[:, 0].min(), X[:, 0].max(), 30)\n",
    "y = np.linspace(X[:, 1].min(), X[:, 1].max(), 30)\n",
    "z = np.linspace(X[:, 2].min(), X[:, 2].max(), 30)\n",
    "xx, yy, zz = np.meshgrid(x, y, z)\n",
    "grid = np.c_[xx.ravel(), yy.ravel(), zz.ravel()]\n",
    "decision_scores = oc_svm.decision_function(grid)\n",
    "decision_scores = decision_scores.reshape(xx.shape)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=good_points[:, 0],\n",
    "    y=good_points[:, 1],\n",
    "    z=good_points[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color='blue', opacity=0.8),\n",
    "    name='Good (Predicted)'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=defective_points[:, 0],\n",
    "    y=defective_points[:, 1],\n",
    "    z=defective_points[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color='red', opacity=0.8),\n",
    "    name='Defective (Predicted)'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Isosurface(\n",
    "    x=grid[:, 0],\n",
    "    y=grid[:, 1],\n",
    "    z=grid[:, 2],\n",
    "    value=decision_scores.ravel(),\n",
    "    isomin=-0.01,\n",
    "    isomax=0.01,\n",
    "    opacity=0.3,\n",
    "    surface_count=1, \n",
    "    colorscale='Viridis',\n",
    "    name='Decision Boundary'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='One-Class SVM: 3D Decision Boundary with Data Points',\n",
    "    scene=dict(\n",
    "        xaxis_title='Output1',\n",
    "        yaxis_title='Output2',\n",
    "        zaxis_title='Output3',\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0.1, y=0.9, bgcolor='rgba(255,255,255,0.5)'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcd3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Kernel: {oc_svm.kernel}\")\n",
    "print(f\"Gamma: {oc_svm.gamma}\")\n",
    "print(f\"Nu: {oc_svm.nu}\")\n",
    "\n",
    "y_train_pred = oc_svm.predict(X_good) \n",
    "\n",
    "train_accuracy = np.mean(y_train_pred == 1)  \n",
    "y_bad_pred = oc_svm.predict(X_bad) \n",
    "\n",
    "defective_accuracy = np.mean(y_bad_pred == -1) \n",
    "average_accuracy = (train_accuracy + defective_accuracy) / 2\n",
    "\n",
    "print(f\"Average Training Accuracy: {average_accuracy:.2%}\")\n",
    "print(f\"Training Accuracy (Good Data): {train_accuracy:.2%}\")\n",
    "print(f\"Training Accuracy (Defective Data): {defective_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93e245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_good_scaled = scaler.fit_transform(X_good) \n",
    "\n",
    "gamma_values = np.arange(0.02, 5.0, 0.02) \n",
    "nu_values = np.arange(0.02, 0.1, 0.02)\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for gamma in gamma_values:\n",
    "    for nu in nu_values:\n",
    "        try:\n",
    "            oc_svm = OneClassSVM(kernel='rbf', gamma=gamma, nu=nu)\n",
    "            oc_svm.fit(X_good)  \n",
    "\n",
    "            y_train_pred = oc_svm.predict(X_good)\n",
    "            train_accuracy = np.mean(y_train_pred == 1)  # 良品データの正解率\n",
    "\n",
    "            if train_accuracy > best_train_accuracy:\n",
    "                best_train_accuracy = train_accuracy\n",
    "                best_params = {'gamma': gamma, 'nu': nu}\n",
    "\n",
    "            print(f\"Gamma: {gamma}, Nu: {nu}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Error with gamma={gamma}, nu={nu}: {e}\")\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(f\"Gamma: {best_params['gamma']}, Nu: {best_params['nu']}\")\n",
    "print(f\"Best Training Accuracy: {best_train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672af7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('outputs_with_labels.csv')\n",
    "\n",
    "X = data[['Output1', 'Output2', 'Output3']].values\n",
    "true_labels = data['True Label'].values  \n",
    "good_data = data[data['True Label'].isin([0, 1, 2])]\n",
    "X_good = good_data[['Output1', 'Output2', 'Output3']].values\n",
    "bad_data = data[data['True Label'] == 3]\n",
    "X_bad = bad_data[['Output1', 'Output2', 'Output3']].values\n",
    "sdata = pd.read_csv('soutputs_with_labels.csv')\n",
    "X = sdata[['Output1', 'Output2', 'Output3']].values\n",
    "strue_labels = sdata['True Label'].values \n",
    "sgood_data = sdata[sdata['True Label'].isin([0, 1, 2])]\n",
    "sX_good = sgood_data[['Output1', 'Output2', 'Output3']].values  \n",
    "y_good = np.ones(len(sgood_data), dtype=int) \n",
    "sbad_data = sdata[sdata['True Label'] == 3]\n",
    "X_bad = sbad_data[['Output1', 'Output2', 'Output3']].values\n",
    "y_bad = -1 * np.ones(len(sbad_data), dtype=int) \n",
    "X_selected = np.concatenate([sX_good, X_bad], axis=0)\n",
    "y_selected = np.concatenate([y_good, y_bad], axis=0) \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "oc_svm = OneClassSVM(kernel='rbf', gamma=0.4, nu=0.02)\n",
    "oc_svm.fit(X_good) \n",
    "\n",
    "y_pred = oc_svm.predict(X_selected)\n",
    "print(classification_report(y_selected, y_pred, target_names=['Defective', 'Good']))\n",
    "print(f\"Kernel: {oc_svm.kernel}\")\n",
    "print(f\"Gamma: {oc_svm.gamma}\")\n",
    "print(f\"Nu: {oc_svm.nu}\")\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "recall = recall_score(y_selected, y_pred, pos_label=1) \n",
    "print(f\"Recall (Good): {recall:.4f}\")\n",
    "precision = precision_score(y_selected, y_pred, pos_label=1)\n",
    "print(f\"Precision (Good): {precision:.4f}\")\n",
    "f1 = f1_score(y_selected, y_pred, pos_label=1)\n",
    "print(f\"F1-Score (Good): {f1:.4f}\")\n",
    "accuracy = accuracy_score(y_selected, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddcc24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "\n",
    "cm = confusion_matrix(y_selected, y_pred)\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] \n",
    "    plt.figure(figsize=(6, 4.5))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "class_names = ['Defective', 'Good']\n",
    "\n",
    "plot_confusion_matrix(cm, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8985437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "y_scores = oc_svm.decision_function(X_scaled) \n",
    "y_true = (y_selected != -1).astype(int)     \n",
    "\n",
    "thresholds = np.linspace(min(y_scores), max(y_scores), 100)\n",
    "\n",
    "tpr_list = []\n",
    "fpr_list = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_scores >= threshold).astype(int)\n",
    "    \n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1)) \n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))  \n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0)) \n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))  \n",
    "\n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  \n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0  \n",
    "\n",
    "    tpr_list.append(TPR)\n",
    "    fpr_list.append(FPR)\n",
    "\n",
    "roc_auc = auc(fpr_list, tpr_list)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr_list, tpr_list, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')  # 対角線\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Score: {roc_auc:.4f}\")\n",
    "print(y_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324924f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_scores = oc_svm.decision_function(X_scaled) \n",
    "y_true = (y_selected == -1).astype(int) \n",
    "thresholds = np.linspace(min(y_scores), max(y_scores), 100)\n",
    "\n",
    "tpr_list = []\n",
    "fpr_list = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_scores <= threshold).astype(int)\n",
    "    \n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))  \n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1)) \n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))  \n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0)) \n",
    "\n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  \n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0  \n",
    "\n",
    "    tpr_list.append(TPR)\n",
    "    fpr_list.append(FPR)\n",
    "\n",
    "roc_auc = auc(fpr_list, tpr_list)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr_list, tpr_list, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--') \n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Score: {roc_auc:.4f}\")\n",
    "print(y_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67301f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74929b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
